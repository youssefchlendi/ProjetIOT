{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/youssefchlendi/ProjetIOT/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet IOT : Détection d'objets en temps réel avec YOLOv4Sticky Keys\n",
    "\n",
    "## Aperçu du projet\n",
    "Ce projet démontre la détection d'objets en temps réel en utilisant le modèle YOLOv4. Les objets détectés sont pour l'instant imprimés dans la console, à l'avenir nous enverrons les données à un broker MQTT et les stockerons dans une base de données. Le projet est implémenté en Python et utilise OpenCV, NumPy, et d'autres bibliothèques pour les tâches de vision par ordinateur.\n",
    "\n",
    "## Étapes à suivre\n",
    "\n",
    "1. **Importer des bibliothèques** : Importez les bibliothèques nécessaires, notamment OpenCV, NumPy, PIL, etc.\n",
    "2. **Clonage du dépôt YOLOv4 Dépôt du Darknet**: Clonez le dépôt YOLOv4 depuis GitHub.\n",
    "3. **Configuration YOLOv4** : Modifier le Makefile pour activer le GPU, OpenCV, et les autres configurations nécessaires.\n",
    "4. **Compilation de YOLOv4** : Compilez le code de YOLOv4.\n",
    "5. **Téléchargement des poids pré-entraînés** : Téléchargez les poids pré-entraînés de YOLOv4.\n",
    "6. **Charge du modèle YOLOv4** : Charger le modèle YOLOv4 avec la configuration et les poids.\n",
    "7. **Test du modèle YOLOv4** : Testez le modèle YOLOv4 sur une liste d'images.\n",
    "\n",
    "## Étapes détaillées\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-xIQc8P2Ch4"
   },
   "source": [
    "Importer des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lfEAFBGe0nsS"
   },
   "outputs": [],
   "source": [
    "# Installations des bibliothèques nécessaires\n",
    "!pip install paho-mqtt\n",
    "!pip install pymong\n",
    "\n",
    "# Importation des bibliothèques nécessaires\n",
    "\n",
    "from IPython.display import display, Javascript, Image\n",
    "from google.colab.output import eval_js\n",
    "from google.colab.patches import cv2_imshow\n",
    "from base64 import b64decode, b64encode\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n",
    "import io\n",
    "import html\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gq8jCpBn08Xn"
   },
   "source": [
    "Clonage du dépôt YOLOv4 Dépôt du Darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J393vwpI2TCL",
    "outputId": "9d59a532-4f9f-4eb2-b689-217269ddec68"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/AlexeyAB/darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aywEftTCd0Uy",
    "outputId": "872a0bdb-0eb7-4128-f8cc-e4abaac1622e"
   },
   "outputs": [],
   "source": [
    "%cd darknet\n",
    "# - Activation support OpenCV (OPENCV=1) \n",
    "!sed -i 's/OPENCV=0/OPENCV=1/' Makefile\n",
    "# - Activation support GPU (GPU=1) \n",
    "!sed -i 's/GPU=0/GPU=1/' Makefile\n",
    "# - Activation support cuDNN (CUDNN=1) \n",
    "!sed -i 's/CUDNN=0/CUDNN=1/' Makefile\n",
    "# - Demi-precision en virgule flottante dans cuDNN (CUDNN_HALF=1) \n",
    "!sed -i 's/CUDNN_HALF=0/CUDNN_HALF=1/' Makefile\n",
    "# - Construction en tant que bibliothèque d'objets partagés (LIBSO=1)\n",
    "!sed -i 's/LIBSO=0/LIBSO=1/' Makefile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c55wAhl_d6Qa"
   },
   "source": [
    " Compilation de YOLOv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rlcIgGN2ZI3",
    "outputId": "ae632c33-bd30-4663-e8d8-daf6a99adb16"
   },
   "outputs": [],
   "source": [
    "# Compilation de Darknet\n",
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5NlKe99u0rwe",
    "outputId": "6ddde7ef-40e1-447a-e218-242692aaca0c"
   },
   "outputs": [],
   "source": [
    "# Téléchargement des poids pré-entraînés YOLOv4-CSP\n",
    "!wget \\\n",
    "  --load-cookies /tmp/cookies.txt \\\n",
    "  \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt \\\n",
    "  --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1V3vsIaxAlGWvK4Aar9bAiK5U0QFttKwq' \\\n",
    "    -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1V3vsIaxAlGWvK4Aar9bAiK5U0QFttKwq\" \\\n",
    "      -O yolov4-csp.weights && rm -rf /tmp/cookies.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Téléchargement des poids pré-entraînés YOLOv4\n",
    "!wget https://github.com/AlexeyAB/darknet/releases/download/yolov4/yolov4.weights -O yolov4.weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXvyx8aT2n0f"
   },
   "source": [
    "## Exécution du modele\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9hLJtff2w1T",
    "outputId": "29f73694-f793-433f-cd55-77cace0cdb94"
   },
   "outputs": [],
   "source": [
    "# Importation des bibliothèques\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "from google.colab.patches import cv2_imshow  # Import cv2_imshow for displaying images in Colab\n",
    "\n",
    "# Path de configuration, de données et de poids\n",
    "cfg_path = \"cfg/yolov4.cfg\"\n",
    "data_path = \"data/coco.names\" \n",
    "weights_path = \"yolov4.weights\"\n",
    "\n",
    "# Methode pour charger le réseau de neurones\n",
    "def load_network(cfg_path, data_path, weights_path):\n",
    "    net = cv2.dnn.readNet(weights_path, cfg_path)\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    # Load class names\n",
    "    with open(data_path, 'r') as f:\n",
    "        class_names = f.read().strip().split('\\n')\n",
    "\n",
    "    return net, output_layers, class_names\n",
    "\n",
    "# Charger le réseau de neurones\n",
    "network, output_layers, class_names = load_network(cfg_path, data_path, weights_path)\n",
    "\n",
    "# Methode pour détecter les objets\n",
    "def darknet_helper(img, width, height):\n",
    "    # Preparation de l'image\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255.0, (width, height), swapRB=True, crop=False)\n",
    "    \n",
    "    # Charger l'image dans le réseau de neurones\n",
    "    network.setInput(blob)\n",
    "\n",
    "    # Exécution de l'inference\n",
    "    outputs = network.forward(output_layers)\n",
    "\n",
    "    # Détecter les objets\n",
    "    detections = []\n",
    "    # Ce bloc de code est chargé de traiter les sorties du réseau neuronal pour détecter des objets dans une image. Voici un aperçu de ce qu'il fait :\n",
    "\n",
    "    for output in outputs:\n",
    "\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            # - Obtenir l'identifiant de la classe et le score de confiance de l'objet actuel.\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            \n",
    "            # - Vérifier si le score de confiance est supérieur à un seuil (0.5).\n",
    "            if confidence > 0.5:  \n",
    "                # - Calculez les coordonnées du centre (x, y), la largeur et la hauteur de la boîte de délimitation.\n",
    "                center_x = int(detection[0] * img.shape[1])\n",
    "                center_y = int(detection[1] * img.shape[0])\n",
    "                \n",
    "                w = int(detection[2] * img.shape[1])\n",
    "                h = int(detection[3] * img.shape[0])\n",
    "                left = int(center_x - w / 2)\n",
    "                top = int(center_y - h / 2)\n",
    "                \n",
    "                # - Ajouter le nom de la classe, le score de confiance et les coordonnées de la boîte de délimitation à la liste des détections.\n",
    "                detections.append((class_names[class_id], confidence, (left, top, left + w, top + h)))\n",
    "\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzLavbbz-R4F"
   },
   "source": [
    "# Exécuter le Védio de Webcam & Envoyer les informations de détection au broker MQTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jWMTVfZp4rAu",
    "outputId": "4e194c67-a634-4d79-f770-2d621ff853bf"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from google.colab.patches import cv2_imshow  \n",
    "from darknet import *  \n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Methode pour obtenir une image aléatoire\n",
    "def get_random_image():\n",
    "    url = \"https://random.imagecdn.app/1500/1500\"\n",
    "    response = requests.get(url)\n",
    "    image = Image.open(BytesIO(response.content))\n",
    "    # Convertir l'image en RGB (OpenCV utilise BGR)\n",
    "    return cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Créer un répertoire pour enregistrer les images avec détections\n",
    "os.makedirs('/content/images', exist_ok=True)\n",
    "\n",
    "# Boucle pour afficher 10 images aléatoires avec détections\n",
    "for count in range(10):\n",
    "    frame = get_random_image()\n",
    "    cv2_imshow(frame)  # Afficher l'image\n",
    "    \n",
    "    # Créer un tableau de zéros pour stocker les coordonnées des boîtes de délimitation\n",
    "    bbox_array = np.zeros([frame.shape[0], frame.shape[1], 4], dtype=np.uint8)\n",
    "\n",
    "    try:\n",
    "        # Redimensionner l'image à 416x416 pour la détection\n",
    "        img_resized = cv2.resize(frame, (1500, 1500), interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        # Détecter les objets dans l'image\n",
    "        detections = darknet_helper(img_resized, 1500, 1500)\n",
    "        print(\"Detections:\", detections)\n",
    "\n",
    "        # Verifier si des objets ont été détectés\n",
    "        if detections:\n",
    "            # Dessiner les boîtes de délimitation sur l'image\n",
    "            for detection in detections:\n",
    "                label, confidence, (left, top, right, bottom) = detection\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (255, 0, 0), 2)\n",
    "                cv2.putText(frame, f\"{label} [{confidence:.2f}]\", (left, top - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
    "\n",
    "            # Enregistrer l'image avec les détections\n",
    "            image_path = f'/content/images/detected_{count}.jpg'\n",
    "            cv2.imwrite(image_path, frame)\n",
    "            print(f\"Image saved at {image_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error during detection:\", e)\n",
    "\n",
    "    # Afficher l'image avec les détections\n",
    "    cv2_imshow(frame)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "YjOa8bVj3mwV"
   ],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
